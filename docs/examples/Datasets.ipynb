{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with MillionTrees datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TreePoints', 'TreeBoxes', 'TreePolygons']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'examples':\n",
    "    sys.path.append(\"../\")\n",
    "    \n",
    "import milliontrees\n",
    "from torchvision import transforms\n",
    "\n",
    "# List available datasets\n",
    "print(milliontrees.benchmark_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general workflow is to \n",
    "1. Select and optionally download a dataset\n",
    "2. Load the train and test splits from the dataset\n",
    "3. Create the dataloader, with optional additional transforms, for how to preprocess images, and optionally augment, input images and metadata\n",
    "4. Use these dataloaders to train models in native pytorch or pytorch lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and optionally download a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/ewhite/b.weinstein/miniconda3/envs/MillionTrees/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/blue/ewhite/b.weinstein/miniconda3/envs/MillionTrees/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# Load the box dataset\n",
    "from milliontrees import get_dataset\n",
    "dataset = get_dataset(\"TreeBoxes\", root_dir=\"/orange/ewhite/DeepForest/MillionTrees/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train and test splits from the dataset\n",
    "\n",
    "Datasets are split into groups of images based on task. For example, 'train' versus 'test' or 'zero_shot_train' and 'zero_shot_test'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length: 2\n",
      "Image shape: (81, 2), Image type: <class 'numpy.ndarray'>\n",
      "Label shape: torch.Size([3, 448, 448]), Label type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from milliontrees.common.data_loaders import get_train_loader\n",
    "\n",
    "train_dataset = dataset.get_subset(\"train\")\n",
    "\n",
    "# View the first image in the dataset\n",
    "image, label, metadata = train_dataset[0]\n",
    "print(f\"Metadata length: {len(metadata)}\")\n",
    "print(f\"Image shape: {image.shape}, Image type: {type(image)}\")\n",
    "print(f\"Label shape: {label.shape}, Label type: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: You are loading the entire dataset. Consider using dataset.get_subset('train') for a portion of the dataset if intended.\n",
      "Targets is a list of dictionaries with the following keys:  dict_keys(['boxes', 'labels'])\n",
      "Image shape: torch.Size([2, 3, 448, 448]), Image type: <class 'torch.Tensor'>\n",
      "Annotation shape of the first image: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_train_loader(\"standard\", train_dataset, batch_size=2)\n",
    "\n",
    "# Show one batch of the loader\n",
    "for metadata, image, targets in train_loader:\n",
    "    print(\"Targets is a list of dictionaries with the following keys: \", targets[0].keys())\n",
    "    print(f\"Image shape: {image.shape}, Image type: {type(image)}\")\n",
    "    print(f\"Annotation shape of the first image: {targets[0]['boxes'].shape}\")\n",
    "    break  # Just show the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: /blue/ewhite/b.weinstein/miniconda3/envs/MillionTrees/lib/python3.10/site-packages/deepforest/data/deepforest_config.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: /blue/ewhite/b.weinstein/miniconda3/envs/MillionTrees/lib/python3.10/site-packages/deepforest/data/deepforest_config.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\n",
      "  | Name       | Type                  | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model      | RetinaNet             | 32.1 M | train\n",
      "1 | iou_metric | IntersectionOverUnion | 0      | train\n",
      "2 | mAP_metric | MeanAveragePrecision  | 0      | train\n",
      "-------------------------------------------------------------\n",
      "31.9 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "32.1 M    Total params\n",
      "128.592   Total estimated model params size (MB)\n",
      "204       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "UserWarning: Total length of `list` across ranks is zero. Please make sure this was your intention.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:33<00:00,  0.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:33<00:00,  0.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from deepforest import main\n",
    "\n",
    "# Create a DeepForest model\n",
    "m = main.deepforest()\n",
    "\n",
    "# Load the pre-trained tree model\n",
    "m.load_model(\"Weecology/DeepForest-tree\")\n",
    "\n",
    "# Create a trainer with fast development run enabled\n",
    "m.create_trainer(fast_dev_run=True)\n",
    "m.config[\"train\"][\"csv_file\"] =\"<dummy file, existing dataloader>\"\n",
    "m.trainer.fit(m, train_loader)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MillionTrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
